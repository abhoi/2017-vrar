---
layout: post
title: ARKit + CoreLocation Navigation
published: true
---

![Header Image]({{ site.url }}/assets/ar_head.jpg)

## Navigation using Augmented Reality!

For the Student's Choice Presentation portion of the CS491 - Virtual and Augmented Reality class, I would like to talk about augmented reality based navigation. Particularly, this specific application of Apple's ARKit to develop a unique navigation application using AR and iPhone's camera.

The application was developed by [Andrew Hart](https://github.com/ProjectDent). The application cleverly uses two aspects of Apple's frameworks: ARKit and CoreLocation. It uses GPS data in addition to highly accurate AR to overlay information onto the screen. The first application of this is when you want to find a location on maps and need walking directions to the location. A video demonstrating the storyboard is as follows:

![Demonstration]({{ site.url }}/assets/ar2.gif)

A second great use is to highlight common buildings and city structures when panning over them. An example:

![Demonstration 2]({{ site.url }}/assets/ar1.gif)

## Cool! But what's the technical details? Pros vs Cons? Is it good?

First, I want to talk about the location services part of the application. How does the application get location data? How does it work with placing nodes and 3D objects in the AR space in your phone? What is the accuracy? Are there alternative methods to getting location data?

1. **CLLocation:** The application gets the user's current location using Apple's [CLLocationManager](https://developer.apple.com/documentation/corelocation/cllocationmanager) class. An object of that class can be declared which can be configured further to specify **accuracy, type of authorization, delegates**, etc. The CLLocationManger.location property returns a [CLLocation](https://developer.apple.com/documentation/corelocation/cllocation) property. This CLLocation property holds the appropriate data such as **latitude, longitude, altitude**, etc. An example configuration of the CLLocationManager which I implemented is:

		locationManager.delegate = self
    	locationManager.desiredAccuracy = kCLLocationAccuracyBest
		locationManager.requestAlwaysAuthorization()
		locationManager.distanceFilter = 50
    	locationManager.startUpdatingLocation()

The location manager sets the current ViewController as the delegate, sets desired accuracy to best, requests authorization to access location always (even when the application is in background), sets the distance filter to 50m, and allows the location manager to update location in a set time interval.

2. **Transform Matrix**: Getting the user's location is great. You get the latitude and longitude of the user's current location. However, this information is completely futile in its current form with respect to ARKit. This is because ARKit has its own **coordinate space**. This can be visualized as:

![ARKit Coordinates](https://cdn-images-1.medium.com/max/800/1*IRvOJvHSBOpLxbdGCzck-g.png)

Thus, if you move in the **-Z** direction, you move forward in the ARScene space. **+X** would move you right. **+Y** would move you up. This sets the tone that you cannot directly use latitude and longitude data in ARKit space. Imagine you want to put a sphere in a specific location but you do not know the transform location of that object, only the latitude and longtiude. How does one go about transforming the coordinate system into a the 3D space that ARKit can understand? This is where some **Computer Graphics** knowledge comes into picture. We use the concept of representing coordinate systems in terms of 4x4 **matrices**:

![Matrix](https://cdn-images-1.medium.com/max/800/1*6aCjMoJnuQov_GMoUTqwCw.png)

Using this representation, you can perform operations such as **translation**:

		[1 0 0 X]   [x]   [ x + X*w ]
		[0 1 0 Y] x [y] = [ y + Y*w ]
		[0 0 1 Z]   [z]   [ z + Z*w ]
		[0 0 0 1]   [w]   [ W       ]	

and **rotation**:

![Rotation Matrix](https://cdn-images-1.medium.com/max/800/1*FE4m9047G3ixBAvJlvYpaw.png)

You can perform SIMD (Single instruction multiple data) operations to get a transformed matrix. This should allow you to get a 4x4 matrix representation that you can assign as a node's transform property to place it into the ARKit space.

3. **Tree Node Structure**: How does Apple's ARKit know how to structure nodes in your ARScene? This video visually and clearly explains how this works:



References:

[9to5mac](https://9to5mac.com/2017/07/21/arkit-augmented-reality-navigation/)

[Github Project](https://github.com/ProjectDent/ARKit-CoreLocation)

[Twitter Demonstration](https://twitter.com/AndrewProjDent/status/888380207962443777?ref_src=twsrc%5Etfw&ref_url=https%3A%2F%2F9to5mac.com%2F2017%2F07%2F21%2Farkit-augmented-reality-navigation%2F)
