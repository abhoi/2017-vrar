---
layout: post
title: ARKit + CoreLocation Navigation
published: true
---

![Header Image]({{ site.url }}/assets/ar_head.jpg)

## Navigation using Augmented Reality!

For the Student's Choice Presentation portion of the CS491 - Virtual and Augmented Reality class, I would like to talk about augmented reality based navigation. Particularly, this specific application of Apple's ARKit to develop a unique navigation application using AR and iPhone's camera.

The application was developed by [Andrew Hart](https://github.com/ProjectDent). The application cleverly uses two aspects of Apple's frameworks: ARKit and CoreLocation. It uses GPS data in addition to highly accurate AR to overlay information onto the screen. The first application of this is when you want to find a location on maps and need walking directions to the location. A video demonstrating the storyboard is as follows:

![Demonstration]({{ site.url }}/assets/ar2.gif)

A second great use is to highlight common buildings and city structures when panning over them. An example:

![Demonstration 2]({{ site.url }}/assets/ar1.gif)

## Cool! But what's the technical details? Pros vs Cons? Is it good?

First, I want to talk about the location services part of the application. How does the application get location data? How does it work with placing nodes and 3D objects in the AR space in your phone? What is the accuracy? Are there alternative methods to getting location data?

- **CLLocation:** The application gets the user's current location using Apple's [CLLocationManager](https://developer.apple.com/documentation/corelocation/cllocationmanager) class. An object of that class can be declared which can be configured further to specify **accuracy, type of authorization, delegates**, etc. The CLLocationManger.location property returns a [CLLocation](https://developer.apple.com/documentation/corelocation/cllocation) property. This CLLocation property holds the appropriate data such as **latitude, longitude, altitude**, etc. An example configuration of the CLLocationManager which I implemented is:

		locationManager.delegate = self
		locationManager.desiredAccuracy = kCLLocationAccuracyBest
		locationManager.requestAlwaysAuthorization()
		locationManager.distanceFilter = 50
		locationManager.startUpdatingLocation()

The location manager sets the current ViewController as the delegate, sets desired accuracy to best, requests authorization to access location always (even when the application is in background), sets the distance filter to 50m, and allows the location manager to update location in a set time interval.

- **Transform Matrix**: Getting the user's location is great. You get the latitude and longitude of the user's current location. However, this information is completely futile in its current form with respect to ARKit. This is because ARKit has its own **coordinate space**. This can be visualized as:

![ARKit Coordinates](https://cdn-images-1.medium.com/max/800/1*IRvOJvHSBOpLxbdGCzck-g.png)

Thus, if you move in the **-Z** direction, you move forward in the ARScene space. **+X** would move you right. **+Y** would move you up. This sets the tone that you cannot directly use latitude and longitude data in ARKit space. Imagine you want to put a sphere in a specific location but you do not know the transform location of that object, only the latitude and longtiude. How does one go about transforming the coordinate system into a the 3D space that ARKit can understand? This is where some computer graphics knowledge comes into picture. We use the concept of representing coordinate systems in terms of 4x4 **matrices**:

![Matrix](https://cdn-images-1.medium.com/max/800/1*6aCjMoJnuQov_GMoUTqwCw.png)

Using this representation, you can perform operations such as **translation**:

	[1 0 0 X]   [x]   [ x + X*w ]
	[0 1 0 Y] x [y] = [ y + Y*w ]
	[0 0 1 Z]   [z]   [ z + Z*w ]
	[0 0 0 1]   [w]   [ W       ]	

and **rotation**:

![Rotation Matrix](https://cdn-images-1.medium.com/max/800/1*FE4m9047G3ixBAvJlvYpaw.png)

You can perform SIMD (Single instruction multiple data) operations to get a transformed matrix. This should allow you to get a 4x4 matrix representation that you can assign as a node's transform property to place it into the ARKit space.

- **Tree Node Structure**: How does Apple's ARKit know how to structure nodes in your ARScene? This video visually and clearly explains how this works:

[![ARKit Tutorial](http://img.youtube.com/vi/tgPV_cRf2hA/0.jpg)](https://youtu.be/tgPV_cRf2hA?t=1256)

I hope that clearly explains node structure and how to work in that aspect.

- **How good is the accuracy?**: I think the following video gives some intuition as to what the problem is:

[![Accuracy Problem](http://img.youtube.com/vi/6Lo0Z7CkMWw/0.jpg)](https://www.youtube.com/watch?v=6Lo0Z7CkMWw)

The accuracy is **NOT** that good. There is an error of upto **10-20 meters** at a give time depending on the location. This can clearly result in errors depending on the type of location. This is the biggest problem with this idea. ARKit has an error of between a **few meters to a few millimeters**. But a CLLocation has an error of **10-20 meters**! 

- **Alternative Methods to Get Location**: For the user's current location, it is reccommended to use CLLocation as it provides a pretty good estimate for iPhone location. To get Places location and information, you can possibly use [Google Maps/Places SDK](https://developers.google.com/maps/documentation/ios-sdk/) or [Mapbox SDK](https://www.mapbox.com/ios-sdk/).

![Google Maps](https://www.programmableweb.com/wp-content/Google-Maps-for-iOs.jpg)

![Mapbox](https://www.mapbox.com/ios-sdk/api/3.6.4/img/screenshot.png)

## Other Implementations Using the same idea

This project is not the only one doing ARKit + CoreLocation. Some others are:

- **UrbanBird**: [![UrbanBird](http://img.youtube.com/vi/QaJAOtvzxCE/0.jpg)](https://www.youtube.com/watch?v=QaJAOtvzxCE)

- **LocateAR**: [![LocateAR](http://img.youtube.com/vi/FrQ4Oqzdi0Y/0.jpg)](https://www.youtube.com/watch?v=FrQ4Oqzdi0Y)

- **Neon**: [![Neon](http://img.youtube.com/vi/VV9jMjncj2I/0.jpg)](https://www.youtube.com/watch?v=VV9jMjncj2I)

## Conclusion

There are lots of implementations floating around the internet with the same concept. However, until the problem of location accuracy is solved, this implementation will remain as a proof of concept and not develop into a marketable/consumer level application.
References:

[9to5mac](https://9to5mac.com/2017/07/21/arkit-augmented-reality-navigation/)

[Github Project](https://github.com/ProjectDent/ARKit-CoreLocation)

[Twitter Demonstration](https://twitter.com/AndrewProjDent/status/888380207962443777?ref_src=twsrc%5Etfw&ref_url=https%3A%2F%2F9to5mac.com%2F2017%2F07%2F21%2Farkit-augmented-reality-navigation%2F)

[Yat Choi](https://medium.com/@yatchoi/getting-started-with-arkit-real-life-waypoints-1707e3cb1da2)

[Christopher Webb-Orenstein](https://medium.com/journey-of-one-thousand-apps/arkit-and-corelocation-part-one-fc7cb2fa0150)
